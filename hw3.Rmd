---
title: "HW3"
author: "Zhenning Zhang"
date: '2022-12-01'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

https://github.com/ZhenningZhang/STATS506

Question 1

Global level git config:
C:/Users/zzn/.gitconfig
(where zzn is my username in English)

Local level git config:
(It's in git repo's .git folder)

And I am using a Windows machine.

(Since I already have an account in my global gitconfig, so I'm no going to override it with UMich account.)

```{r}
system("cat C:/Users/张振宁/.gitconfig")
```

Commands in Git Bash:

pwd
cd Downloads/STATS506/hw3
git init
git add hw3.Rmd
git add .gitignore
git commit

git remote add origin https://github.com/ZhenningZhang/STATS506.git
git branch -M main
git push -u origin main

```{r}
system("cat .gitignore")
```

Question 2

```{r}
# How I technically can read it line by line
filepath = "hw3data/2020_Business_Academic_QCQ.txt"
con = file(filepath, "r")
readLines(con, n = 1)
```

```{r}
library(data.table)

# but fread is simply too OP
varnames = c("State", "County Code", "Employee Size (5) - Location", "Sales Volume (9) - Location", "Census Tract")

# There is not a lot of variables, so just hard coding
readdata = function(n1=1, n2=10) {
  data = fread(filepath, nrows=n2, select=varnames)
  colnames(data) = c("state", "county_code", "employee_size_location", "sales_volume_location", "census_tract")
  if(n1!=1)
    data = data[-(1:(n1-1)),]
  return(data[complete.cases(data),])
}

readdata(2,7)
```

Question 3

```{r}
AL = readdata(1,1000000)

library(tidyverse)

df1 = AL %>% filter(state=="AL") %>% group_by(census_tract) %>% summarise(employee_size = sum(employee_size_location), sales_volume = sum(sales_volume_location))

head(df1)
```

Question 4

SET GLOBAL local_infile=1;

CREATE DATABASE Hw3db;

CREATE TABLE df1 (
	census_tract int primary key,
    employee_size int,
    sales_volume int
);

```{r}
library(RMySQL)

myDB = dbConnect(MySQL(),user="root",password=Sys.getenv("MySQLpassword"),host="localhost",port=3306,db="Hw3db")

# dbWriteTable(myDB,name="df1",value=df1,append = TRUE,row.names = FALSE)
```

Question 5

```{r}
fetch(dbSendQuery(myDB,"SELECT * FROM df1 ORDER BY sales_volume DESC LIMIT 10"))
```

Question 6

git add hw3.Rmd
git commit
git push -u origin main

git branch newbranch
git switch newbranch
git branch -a

(what is remotes/origin/maim here?)
git add hw3.Rmd
git commit
git push -u origin newbranch
(and what is origin means?)


Question 7

```{r}
varnames = c("FIELD19", "FIELD20", "FIELD22", "FIELD45", "FIELD64", "FIELD65")
actualnames = c("wealth","income","home_value","state","county_code","census_tract")

data2 = fread("hw3data/AL.csv",select=varnames)
colnames(data2) = actualnames
data2 = data2 %>% filter(home_value!=0)
```

```{r}
# I'm not sure if it is a good practice just to use same variable names
df2 = data2 %>% group_by(census_tract) %>% summarise(income = sum(income), wealth = sum(wealth), home_value = sum(home_value))

head(df2)
```

Question 8

```{r}
# dbWriteTable(myDB,name="df2",value=df2,row.names = FALSE)
```

ALTER TABLE df2
ADD PRIMARY KEY (census_tract);


Question 9

git add hw3.Rmd
git commit
git push -u origin newbranch

git log

Then it shows Author, Date, and Comment of historial commit.
HEAD -> newbranch means the current working branch (i.e. active branch) is "newbranch."


Question 10

```{r}
library(tidycensus)
Sys.setenv("CENSUS_API_KEY"="b63eea5d1b9fe7ddc0e0b8453dc02ee291ca9101")
```

```{r}
data = get_decennial(geography = 'tract', state = '01', variables = c('P008001'))
white = get_decennial(geography = 'tract', state = '01', variables = c('P008003'))[,4]
black = get_decennial(geography = 'tract', state = '01', variables = c('P008004'))[,4]
asian = get_decennial(geography = 'tract', state = '01', variables = c('P008006'))[,4]

data = cbind(data, white, black, asian)
data = data[,-3]
colnames(data)[3:6] = c("total","white","black","asian")
rm(white, black, asian)
```

```{r}
get_decennial(geography = 'tract', state = '01', variables = c('P008001'))
```


```{r}
# But tbh df3 does not match df1 data in terms of population..
data = data %>% mutate(census_tract = str_remove(substr(GEOID,6,9), "^0+"))
df3 = data %>% group_by(census_tract) %>% summarise(total = sum(total), white = sum(white))
df3 = df3 %>% mutate(white_per = white/total)

head(df3)
```

```{r}
# dbWriteTable(myDB,name="df3",value=df3,row.names = FALSE)
```

Question 11

I want to know the education information and rural / city information.

```{r}
# I don't know why, eventually there's only 18 records left
df4 = fetch(dbSendQuery(myDB,"SELECT * FROM df1
JOIN df2 ON df1.census_tract = df2.census_tract
JOIN df3 ON df1.census_tract = df3.census_tract;"))
df4 = df4[,-c(1,4,8)]

head(df4)
```

Question 12

git add hw3.Rmd
git commit
git push -u origin newbranch

git checkout main
git merge newbranch
git push -u origin main

But I did not really see anything indicate merging in git log..

To go back:

git checkout <commit id>
or git restore --source <commit id> <file name>


Question 13

From the model, there is no enough evidence to identify racial bias on income per worker. But it can affect by the small sample size, lack of other variables, or model specification errors.

```{r}
summary(lm(data = df4, log(income/employee_size) ~ log(home_value/employee_size) + log(wealth/employee_size) + white_per))
```


Question 2


Question 1

A core is a part of a processor which does computations. Whereas a node is one of several nodes inside a server, and a node is where CPUs and other components such as memory are installed.

Login node provides interface to the cluster, so users can login to the cluster, modify scripts, and launch jobs.

Compute node is a set of computing resources (CPU, GPU, RAM, ...) to be consumed for virtual machines. 


Question 2

srun --nodes=1 --ntasks=1 --cpus-per-task=2 --mem=32G --time=03:00:00 /bin/bash


Question 3

My scratch path is /scratch/stats506s001f22_class_root/stats506s001f22_class/zzn

ln -s /scratch/stats506s001f22_class_root/stats506s001f22_class/zzn /home/zzn/'DATASCI 506'/sc

It will do nothing to the original directory

